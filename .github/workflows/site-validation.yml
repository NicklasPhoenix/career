name: Site Validation & Testing
on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

jobs:
  validate-site:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          
      - name: Install validation tools
        run: |
          # HTML validator
          npm install -g html-validate
          
          # Link checker
          npm install -g broken-link-checker
          
          # Python tools for advanced validation
          pip install beautifulsoup4 requests lxml xmlschema
          
      - name: Validate HTML structure
        run: |
          echo "üîç Validating HTML files..."
          
          # Check that main pages exist
          REQUIRED_FILES=(
            "index.html"
            "blog/index.html" 
            "guides/index.html"
            "tools/index.html"
            "css/styles.css"
            "sitemap.xml"
          )
          
          for file in "${REQUIRED_FILES[@]}"; do
            if [[ ! -f "$file" ]]; then
              echo "‚ùå Missing required file: $file"
              exit 1
            else
              echo "‚úÖ Found: $file"
            fi
          done
          
          # Validate HTML syntax
          echo "üîç Validating HTML syntax..."
          html-validate *.html blog/*.html guides/*.html tools/*.html || {
            echo "‚ùå HTML validation failed"
            exit 1
          }
          
          echo "‚úÖ HTML structure validation passed"
          
      - name: Validate sitemap.xml
        run: |
          echo "üó∫Ô∏è Validating sitemap.xml..."
          
          # Check XML syntax
          python3 -c "
          import xml.etree.ElementTree as ET
          try:
              tree = ET.parse('sitemap.xml')
              print('‚úÖ Sitemap XML syntax is valid')
          except ET.ParseError as e:
              print(f'‚ùå Sitemap XML syntax error: {e}')
              exit(1)
          "
          
          # Validate sitemap structure and URLs
          python3 << 'EOF'
          import xml.etree.ElementTree as ET
          import re
          from urllib.parse import urlparse
          
          tree = ET.parse('sitemap.xml')
          root = tree.getroot()
          
          # Check namespace
          expected_ns = "http://www.sitemaps.org/schemas/sitemap/0.9"
          if root.tag != f"{{{expected_ns}}}urlset":
              print("‚ùå Invalid sitemap namespace")
              exit(1)
          
          urls = []
          base_url = "https://nicklasphoenix.github.io/career"
          
          for url_elem in root.findall(f".//{{{expected_ns}}}url"):
              loc = url_elem.find(f"{{{expected_ns}}}loc")
              lastmod = url_elem.find(f"{{{expected_ns}}}lastmod")
              priority = url_elem.find(f"{{{expected_ns}}}priority")
              
              if loc is None:
                  print("‚ùå URL missing <loc> element")
                  exit(1)
                  
              url = loc.text
              urls.append(url)
              
              # Validate URL format
              if not url.startswith(base_url):
                  print(f"‚ùå Invalid URL base: {url}")
                  exit(1)
              
              # Validate priority range
              if priority is not None:
                  try:
                      p = float(priority.text)
                      if not 0.0 <= p <= 1.0:
                          print(f"‚ùå Invalid priority {p} for {url}")
                          exit(1)
                  except ValueError:
                      print(f"‚ùå Invalid priority format for {url}")
                      exit(1)
              
              # Validate date format
              if lastmod is not None:
                  date_pattern = r'^\d{4}-\d{2}-\d{2}$'
                  if not re.match(date_pattern, lastmod.text):
                      print(f"‚ùå Invalid date format for {url}: {lastmod.text}")
                      exit(1)
          
          # Check for duplicates
          if len(urls) != len(set(urls)):
              print("‚ùå Duplicate URLs found in sitemap")
              exit(1)
          
          print(f"‚úÖ Sitemap validation passed - {len(urls)} URLs found")
          EOF
          
      - name: Check internal links
        run: |
          echo "üîó Checking internal links..."
          
          python3 << 'EOF'
          import os
          import re
          from pathlib import Path
          import xml.etree.ElementTree as ET
          
          # Get all URLs from sitemap
          tree = ET.parse('sitemap.xml')
          root = tree.getroot()
          ns = "http://www.sitemaps.org/schemas/sitemap/0.9"
          sitemap_urls = set()
          
          for url_elem in root.findall(f".//{{{ns}}}url"):
              loc = url_elem.find(f"{{{ns}}}loc").text
              # Convert to relative path
              rel_path = loc.replace("https://nicklasphoenix.github.io/career", "").lstrip("/")
              if rel_path == "":
                  rel_path = "index.html"
              elif rel_path.endswith("/"):
                  rel_path += "index.html"
              sitemap_urls.add(rel_path)
          
          # Find all HTML files
          html_files = []
          for root_dir, dirs, files in os.walk("."):
              # Skip .git directory
              if ".git" in root_dir:
                  continue
              for file in files:
                  if file.endswith(".html"):
                      html_files.append(os.path.join(root_dir, file))
          
          # Check each HTML file for internal links
          broken_links = []
          wrong_prefix_links = []
          
          for html_file in html_files:
              with open(html_file, 'r', encoding='utf-8') as f:
                  content = f.read()
              
              # Find all href links
              href_pattern = r'href=["\']([^"\']+)["\']'
              links = re.findall(href_pattern, content)
              
              for link in links:
                  # Skip external links
                  if link.startswith(('http://', 'https://', 'mailto:', 'tel:', '#')):
                      continue
                  
                  # Check for missing /career/ prefix
                  if link.startswith(('/blog/', '/guides/', '/tools/')):
                      wrong_prefix_links.append(f"{html_file}: {link}")
                      continue
                  
                  # Check internal /career/ links
                  if link.startswith('/career/'):
                      rel_path = link[8:]  # Remove /career/
                      if rel_path == "":
                          rel_path = "index.html"
                      elif rel_path.endswith("/"):
                          rel_path += "index.html"
                      
                      # Check if target file exists
                      if not os.path.exists(rel_path):
                          broken_links.append(f"{html_file}: {link} -> {rel_path}")
          
          # Report results
          if wrong_prefix_links:
              print("‚ùå Found links missing /career/ prefix:")
              for link in wrong_prefix_links:
                  print(f"  {link}")
              exit(1)
          
          if broken_links:
              print("‚ùå Found broken internal links:")
              for link in broken_links:
                  print(f"  {link}")
              exit(1)
          
          print(f"‚úÖ Internal links validation passed - checked {len(html_files)} HTML files")
          EOF
          
      - name: Validate CSS
        run: |
          echo "üé® Validating CSS..."
          
          # Check CSS file exists and has content
          if [[ ! -s "css/styles.css" ]]; then
            echo "‚ùå CSS file is missing or empty"
            exit 1
          fi
          
          # Check for key CSS classes
          REQUIRED_CLASSES=(
            "\.container"
            "\.main-nav" 
            "\.blog-post"
            "\.cta-box"
            "\.btn"
            "\.card"
          )
          
          for class in "${REQUIRED_CLASSES[@]}"; do
            if ! grep -q "$class" css/styles.css; then
              echo "‚ö†Ô∏è  Warning: Missing CSS class $class"
            else
              echo "‚úÖ Found CSS class: $class"
            fi
          done
          
          # Check for CSS syntax errors (basic)
          python3 << 'EOF'
          import re
          
          with open('css/styles.css', 'r') as f:
              css_content = f.read()
          
          # Basic CSS syntax checks
          open_braces = css_content.count('{')
          close_braces = css_content.count('}')
          
          if open_braces != close_braces:
              print(f"‚ùå CSS syntax error: Mismatched braces ({open_braces} open, {close_braces} close)")
              exit(1)
          
          print("‚úÖ CSS syntax validation passed")
          EOF
          
      - name: Check meta tags and SEO
        run: |
          echo "üîç Checking SEO elements..."
          
          python3 << 'EOF'
          import os
          import re
          from pathlib import Path
          
          html_files = []
          for root_dir, dirs, files in os.walk("."):
              if ".git" in root_dir:
                  continue
              for file in files:
                  if file.endswith(".html"):
                      html_files.append(os.path.join(root_dir, file))
          
          issues = []
          
          for html_file in html_files:
              with open(html_file, 'r', encoding='utf-8') as f:
                  content = f.read()
              
              # Check for title tag
              if not re.search(r'<title[^>]*>.*?</title>', content, re.IGNORECASE):
                  issues.append(f"{html_file}: Missing <title> tag")
              
              # Check for meta description
              if not re.search(r'<meta[^>]*name=["\']description["\'][^>]*>', content, re.IGNORECASE):
                  issues.append(f"{html_file}: Missing meta description")
              
              # Check for meta viewport
              if not re.search(r'<meta[^>]*name=["\']viewport["\'][^>]*>', content, re.IGNORECASE):
                  issues.append(f"{html_file}: Missing viewport meta tag")
              
              # Check for h1 tag
              if not re.search(r'<h1[^>]*>.*?</h1>', content, re.IGNORECASE):
                  issues.append(f"{html_file}: Missing <h1> tag")
          
          if issues:
              print("‚ö†Ô∏è  SEO Issues found:")
              for issue in issues:
                  print(f"  {issue}")
          else:
              print("‚úÖ SEO validation passed")
          EOF
          
      - name: Performance checks
        run: |
          echo "‚ö° Running performance checks..."
          
          # Check file sizes
          python3 << 'EOF'
          import os
          
          large_files = []
          max_html_size = 500 * 1024  # 500KB
          max_css_size = 200 * 1024   # 200KB
          
          for root_dir, dirs, files in os.walk("."):
              if ".git" in root_dir:
                  continue
              for file in files:
                  filepath = os.path.join(root_dir, file)
                  size = os.path.getsize(filepath)
                  
                  if file.endswith('.html') and size > max_html_size:
                      large_files.append(f"{filepath}: {size/1024:.1f}KB (HTML limit: {max_html_size/1024}KB)")
                  elif file.endswith('.css') and size > max_css_size:
                      large_files.append(f"{filepath}: {size/1024:.1f}KB (CSS limit: {max_css_size/1024}KB)")
          
          if large_files:
              print("‚ö†Ô∏è  Large files detected:")
              for file in large_files:
                  print(f"  {file}")
          else:
              print("‚úÖ File size check passed")
          EOF
          
      - name: Accessibility checks
        run: |
          echo "‚ôø Checking accessibility basics..."
          
          python3 << 'EOF'
          import os
          import re
          
          issues = []
          
          for root_dir, dirs, files in os.walk("."):
              if ".git" in root_dir:
                  continue
              for file in files:
                  if file.endswith(".html"):
                      filepath = os.path.join(root_dir, file)
                      with open(filepath, 'r', encoding='utf-8') as f:
                          content = f.read()
                      
                      # Check for images without alt text
                      img_without_alt = re.findall(r'<img(?![^>]*alt=)[^>]*>', content, re.IGNORECASE)
                      if img_without_alt:
                          issues.append(f"{filepath}: {len(img_without_alt)} images missing alt text")
                      
                      # Check for lang attribute
                      if not re.search(r'<html[^>]*lang=["\'][^"\']+["\']', content, re.IGNORECASE):
                          issues.append(f"{filepath}: Missing lang attribute on <html>")
          
          if issues:
              print("‚ö†Ô∏è  Accessibility issues found:")
              for issue in issues:
                  print(f"  {issue}")
          else:
              print("‚úÖ Basic accessibility checks passed")
          EOF
          
      - name: Final validation summary
        run: |
          echo "üéâ Site validation completed!"
          echo ""
          echo "üìä Validation Summary:"
          echo "‚úÖ HTML structure and syntax"
          echo "‚úÖ Sitemap XML validation"
          echo "‚úÖ Internal link checking"
          echo "‚úÖ CSS validation"
          echo "‚úÖ SEO elements check"
          echo "‚úÖ Performance checks"
          echo "‚úÖ Basic accessibility"
          echo ""
          echo "üöÄ Site is ready for deployment!"
